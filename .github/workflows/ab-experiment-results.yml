# Weekly A/B Experiment Results â€” Homepage Category Grid (SMI-2700)
#
# Runs every Monday at 9 AM UTC.
# Queries GA4 for copy_config rate by homepage_ab_variant user property.
# Computes z-test for proportions, reports lift and significance.
# Creates a GitHub issue with results + promotion recommendation.
#
# Baseline (2026-02-21): 1.18% copy_config rate (506 homepage sessions / 6 events)
# Promotion criteria: +20% relative lift (target: 1.42%+), p < 0.05, n >= 500/cohort, runtime >= 7 days

name: Weekly A/B Experiment Results

on:
  schedule:
    - cron: '0 9 * * 1' # Every Monday at 9 AM UTC
  workflow_dispatch:
    inputs:
      create_issue:
        description: 'Create GitHub issue with results'
        required: false
        default: 'true'
        type: boolean

permissions:
  id-token: write
  issues: write

env:
  GA4_PROPERTY_ID: ${{ vars.GA4_PROPERTY_ID }}
  GCP_PROJECT_ID: ${{ vars.GCP_PROJECT_ID }}
  GCP_WIF_PROVIDER: ${{ vars.GCP_WIF_PROVIDER }}
  GCP_SERVICE_ACCOUNT: ${{ vars.GCP_SERVICE_ACCOUNT }}
  EXPERIMENT_START: '2026-02-21'
  BASELINE_RATE: '1.18'
  BASELINE_SESSIONS: '506'
  BASELINE_EVENTS: '6'
  MIN_COHORT_SIZE: '500'
  MIN_RUNTIME_DAYS: '7'
  PROMOTION_LIFT_PCT: '20'

jobs:
  results:
    name: A/B Experiment Results
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Authenticate to Google Cloud
        id: auth
        uses: google-github-actions/auth@v2
        with:
          project_id: ${{ env.GCP_PROJECT_ID }}
          workload_identity_provider: ${{ env.GCP_WIF_PROVIDER }}
          service_account: ${{ env.GCP_SERVICE_ACCOUNT }}
          token_format: access_token
          access_token_scopes: https://www.googleapis.com/auth/analytics.readonly

      - name: Query copy_config by variant
        id: ga4
        continue-on-error: true
        env:
          TOKEN: ${{ steps.auth.outputs.access_token }}
        run: |
          # Days since experiment started
          START_EPOCH=$(date -d "$EXPERIMENT_START" +%s 2>/dev/null || date -j -f "%Y-%m-%d" "$EXPERIMENT_START" +%s)
          NOW_EPOCH=$(date +%s)
          RUNTIME_DAYS=$(( (NOW_EPOCH - START_EPOCH) / 86400 ))
          echo "runtime_days=${RUNTIME_DAYS}" >> "$GITHUB_OUTPUT"

          # Query: sessions by variant (denominator)
          SESSIONS_RESP=$(curl -s -X POST \
            -H "Authorization: Bearer $TOKEN" \
            -H "Content-Type: application/json" \
            -d "{
              \"dateRanges\": [{\"startDate\": \"${EXPERIMENT_START}\", \"endDate\": \"yesterday\"}],
              \"dimensions\": [{\"name\": \"customUser:homepage_ab_variant\"}],
              \"metrics\": [{\"name\": \"sessions\"}]
            }" \
            "https://analyticsdata.googleapis.com/v1beta/${GA4_PROPERTY_ID}:runReport")

          # Query: copy_config events by variant (numerator)
          EVENTS_RESP=$(curl -s -X POST \
            -H "Authorization: Bearer $TOKEN" \
            -H "Content-Type: application/json" \
            -d "{
              \"dateRanges\": [{\"startDate\": \"${EXPERIMENT_START}\", \"endDate\": \"yesterday\"}],
              \"dimensions\": [{\"name\": \"customUser:homepage_ab_variant\"}],
              \"metrics\": [{\"name\": \"eventCount\"}],
              \"dimensionFilter\": {
                \"filter\": {
                  \"fieldName\": \"eventName\",
                  \"stringFilter\": {\"matchType\": \"EXACT\", \"value\": \"copy_config\"}
                }
              }
            }" \
            "https://analyticsdata.googleapis.com/v1beta/${GA4_PROPERTY_ID}:runReport")

          echo "Sessions response: $SESSIONS_RESP" | head -5

          # Parse sessions by variant
          CTRL_SESSIONS=$(echo "$SESSIONS_RESP" | jq -r '.rows[] | select(.dimensionValues[0].value == "control") | .metricValues[0].value' 2>/dev/null || echo "0")
          VARB_SESSIONS=$(echo "$SESSIONS_RESP" | jq -r '.rows[] | select(.dimensionValues[0].value == "variant-b") | .metricValues[0].value' 2>/dev/null || echo "0")
          [ -z "$CTRL_SESSIONS" ] && CTRL_SESSIONS=0
          [ -z "$VARB_SESSIONS" ] && VARB_SESSIONS=0

          # Parse copy_config events by variant
          CTRL_EVENTS=$(echo "$EVENTS_RESP" | jq -r '.rows[] | select(.dimensionValues[0].value == "control") | .metricValues[0].value' 2>/dev/null || echo "0")
          VARB_EVENTS=$(echo "$EVENTS_RESP" | jq -r '.rows[] | select(.dimensionValues[0].value == "variant-b") | .metricValues[0].value' 2>/dev/null || echo "0")
          [ -z "$CTRL_EVENTS" ] && CTRL_EVENTS=0
          [ -z "$VARB_EVENTS" ] && VARB_EVENTS=0

          echo "control: ${CTRL_SESSIONS} sessions, ${CTRL_EVENTS} copy_config"
          echo "variant-b: ${VARB_SESSIONS} sessions, ${VARB_EVENTS} copy_config"

          echo "ctrl_sessions=${CTRL_SESSIONS}" >> "$GITHUB_OUTPUT"
          echo "varb_sessions=${VARB_SESSIONS}" >> "$GITHUB_OUTPUT"
          echo "ctrl_events=${CTRL_EVENTS}" >> "$GITHUB_OUTPUT"
          echo "varb_events=${VARB_EVENTS}" >> "$GITHUB_OUTPUT"

      - name: Compute statistics
        id: stats
        env:
          CTRL_SESSIONS: ${{ steps.ga4.outputs.ctrl_sessions || '0' }}
          VARB_SESSIONS: ${{ steps.ga4.outputs.varb_sessions || '0' }}
          CTRL_EVENTS: ${{ steps.ga4.outputs.ctrl_events || '0' }}
          VARB_EVENTS: ${{ steps.ga4.outputs.varb_events || '0' }}
          RUNTIME_DAYS: ${{ steps.ga4.outputs.runtime_days || '0' }}
        run: |
          # Compute rates and z-test for proportions (two-tailed, normal approximation)
          python3 - <<'PYEOF'
          import os, math, json

          ctrl_n = int(os.environ.get('CTRL_SESSIONS', 0))
          varb_n = int(os.environ.get('VARB_SESSIONS', 0))
          ctrl_k = int(os.environ.get('CTRL_EVENTS', 0))
          varb_k = int(os.environ.get('VARB_EVENTS', 0))
          runtime = int(os.environ.get('RUNTIME_DAYS', 0))
          min_cohort = int(os.environ.get('MIN_COHORT_SIZE', 500))
          min_runtime = int(os.environ.get('MIN_RUNTIME_DAYS', 7))
          target_lift = float(os.environ.get('PROMOTION_LIFT_PCT', 20))
          baseline_rate = float(os.environ.get('BASELINE_RATE', 1.18))

          # Rates
          ctrl_rate = ctrl_k / ctrl_n if ctrl_n > 0 else 0
          varb_rate = varb_k / varb_n if varb_n > 0 else 0

          # Lift
          if ctrl_rate > 0:
              lift_pct = (varb_rate - ctrl_rate) / ctrl_rate * 100
          else:
              lift_pct = 0

          # Z-test for proportions (two-tailed)
          z_score = 0.0
          p_value = 1.0
          if ctrl_n > 0 and varb_n > 0 and (ctrl_k + varb_k) > 0:
              p_pool = (ctrl_k + varb_k) / (ctrl_n + varb_n)
              se = math.sqrt(p_pool * (1 - p_pool) * (1/ctrl_n + 1/varb_n))
              if se > 0:
                  z_score = (varb_rate - ctrl_rate) / se
                  # Approximation: p-value from standard normal CDF
                  # Using error function approximation
                  abs_z = abs(z_score)
                  t = 1 / (1 + 0.2316419 * abs_z)
                  poly = t * (0.319381530 + t * (-0.356563782 + t * (1.781477937 + t * (-1.821255978 + t * 1.330274429))))
                  p_value = 2 * (1 - (1 / math.sqrt(2 * math.pi)) * math.exp(-abs_z**2 / 2) * (1 - poly))
                  p_value = max(0.0, min(1.0, p_value))

          # Verdict
          enough_runtime = runtime >= min_runtime
          enough_sample = min(ctrl_n, varb_n) >= min_cohort
          significant = p_value < 0.05
          positive_lift = lift_pct >= target_lift

          if not enough_runtime:
              verdict = "WAITING â€” experiment has not run for the minimum 7 days yet"
              recommendation = "wait"
          elif not enough_sample:
              verdict = f"WAITING â€” insufficient sample size (need {min_cohort}/cohort, have {min(ctrl_n, varb_n)})"
              recommendation = "wait"
          elif significant and positive_lift:
              verdict = f"PROMOTE â€” variant-b wins (+{lift_pct:.1f}% lift, p={p_value:.3f})"
              recommendation = "promote"
          elif significant and lift_pct < 0:
              verdict = f"REVERT â€” variant-b hurts ({lift_pct:.1f}% lift, p={p_value:.3f})"
              recommendation = "revert"
          elif not significant and enough_sample:
              verdict = f"NO EFFECT â€” no significant difference detected (lift={lift_pct:.1f}%, p={p_value:.3f})"
              recommendation = "no_effect"
          else:
              verdict = f"INCONCLUSIVE â€” more data needed (lift={lift_pct:.1f}%, p={p_value:.3f})"
              recommendation = "wait"

          print(f"ctrl_rate={ctrl_rate*100:.4f}")
          print(f"varb_rate={varb_rate*100:.4f}")
          print(f"lift_pct={lift_pct:.2f}")
          print(f"z_score={z_score:.3f}")
          print(f"p_value={p_value:.4f}")
          print(f"verdict={verdict}")
          print(f"recommendation={recommendation}")

          # Write to GITHUB_OUTPUT
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"ctrl_rate={ctrl_rate*100:.4f}\n")
              f.write(f"varb_rate={varb_rate*100:.4f}\n")
              f.write(f"lift_pct={lift_pct:.2f}\n")
              f.write(f"z_score={z_score:.3f}\n")
              f.write(f"p_value={p_value:.4f}\n")
              f.write(f"verdict={verdict}\n")
              f.write(f"recommendation={recommendation}\n")
          PYEOF

      - name: Create GitHub issue with results
        if: ${{ github.event.inputs.create_issue != 'false' }}
        env:
          GH_TOKEN: ${{ github.token }}
          RUNTIME: ${{ steps.ga4.outputs.runtime_days }}
          CTRL_N: ${{ steps.ga4.outputs.ctrl_sessions }}
          VARB_N: ${{ steps.ga4.outputs.varb_sessions }}
          CTRL_K: ${{ steps.ga4.outputs.ctrl_events }}
          VARB_K: ${{ steps.ga4.outputs.varb_events }}
          CTRL_RATE: ${{ steps.stats.outputs.ctrl_rate }}
          VARB_RATE: ${{ steps.stats.outputs.varb_rate }}
          LIFT: ${{ steps.stats.outputs.lift_pct }}
          Z: ${{ steps.stats.outputs.z_score }}
          P: ${{ steps.stats.outputs.p_value }}
          VERDICT: ${{ steps.stats.outputs.verdict }}
          REC: ${{ steps.stats.outputs.recommendation }}
        run: |
          WEEK=$(date +"%Y-%m-%d")

          # Choose emoji based on recommendation
          case "$REC" in
            promote) EMOJI="ðŸŸ¢" ;;
            revert)  EMOJI="ðŸ”´" ;;
            wait)    EMOJI="ðŸŸ¡" ;;
            *)       EMOJI="âšª" ;;
          esac

          BODY="## ${EMOJI} Homepage A/B Experiment Results â€” ${WEEK}

**Experiment**: Category Grid vs Control (Variant B vs Control)
**Runtime**: ${RUNTIME} days (started 2026-02-21)
**Metric**: \`copy_config\` event rate

### Results

| Cohort | Sessions | copy_config events | Rate |
|--------|----------|--------------------|------|
| control | ${CTRL_N} | ${CTRL_K} | ${CTRL_RATE}% |
| variant-b | ${VARB_N} | ${VARB_K} | ${VARB_RATE}% |

**Lift**: ${LIFT}% | **z-score**: ${Z} | **p-value**: ${P}

### Verdict

> ${VERDICT}

### Promotion Criteria

| Criterion | Required | Status |
|-----------|----------|--------|
| Runtime | â‰¥ 7 days | ${RUNTIME} days |
| Sample size | â‰¥ 500/cohort | min(${CTRL_N}, ${VARB_N}) |
| Lift | â‰¥ +20% relative | ${LIFT}% |
| Significance | p < 0.05 | p = ${P} |

### Baseline (pre-experiment)

copy_config rate: 1.18% (6 events / 506 sessions, 30-day window ending 2026-02-21)

---

**Next action** (if PROMOTE): Set \`HOMEPAGE_AB_ENABLED=false\`, update homepage to always show the category grid, then redeploy.
**Kill switch**: Set \`HOMEPAGE_AB_ENABLED=false\` in Vercel dashboard to disable experiment immediately.

_Auto-generated by [ab-experiment-results.yml](/.github/workflows/ab-experiment-results.yml) | SMI-2700_"

          gh issue create \
            --repo smith-horn/skillsmith \
            --title "${EMOJI} A/B Results (${WEEK}): Homepage Category Grid â€” ${VERDICT}" \
            --body "$BODY" \
            --label "analytics"
